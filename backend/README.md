# APIBR - API REST para Web Scraping Local

Uma API REST profissional e production-ready para web scraping, desenvolvida para substituir a necessidade do Apify com alta performance, modularidade e recursos avan√ßados.

## üöÄ Caracter√≠sticas Principais

- **Pool de Browsers**: Gest√£o inteligente de recursos com Puppeteer
- **Cache Redis**: Sistema de cache com TTL configur√°vel
- **Rate Limiting**: Controle por IP e API Key
- **Jobs Ass√≠ncronos**: Sistema completo com webhooks
- **M√©tricas Prometheus**: Observabilidade completa
- **Documenta√ß√£o Swagger**: API auto-documentada
- **Docker Support**: Deploy simplificado
- **Graceful Shutdown**: Cleanup seguro de recursos
- **Error Recovery**: Retry exponencial autom√°tico

## üìã Requisitos

- Node.js 18+
- Redis (opcional, para cache)
- Docker & Docker Compose (para deploy)

## üõ†Ô∏è Instala√ß√£o R√°pida

### M√©todo 1: Docker (Recomendado)

```bash
# Clone o reposit√≥rio
git clone <repository-url>
cd APIBR

# Configure as vari√°veis de ambiente
cp .env.example .env

# Inicie com Docker
docker-compose up -d
```

### M√©todo 2: Instala√ß√£o Local

```bash
# Clone o reposit√≥rio
git clone <repository-url>
cd APIBR

# Instale as depend√™ncias
npm install

# Configure as vari√°veis de ambiente
cp .env.example .env

# Inicie o servidor
npm start
```

## üîß Configura√ß√£o

### Vari√°veis de Ambiente

```env
# Servidor
PORT=3000
NODE_ENV=development

# Pool de Browsers
BROWSER_POOL_SIZE=5
BROWSER_HEADLESS=true
BROWSER_TIMEOUT=30000

# Redis (Cache)
REDIS_URL=redis://localhost:6379
CACHE_TTL=3600

# Rate Limiting
RATE_LIMIT_WINDOW=900000
RATE_LIMIT_MAX=100

# Seguran√ßa
API_KEYS=your-api-key-1,your-api-key-2

# Logs
LOG_LEVEL=info
LOG_FORMAT=json
```

## üìö Uso da API

### Endpoints Principais

- `POST /api/scrape` - Scraping s√≠ncrono
- `POST /api/scrape/async` - Scraping ass√≠ncrono
- `GET /api/jobs/:id` - Status de job
- `GET /api/metrics` - M√©tricas Prometheus
- `GET /api/docs` - Documenta√ß√£o Swagger
- `GET /health` - Health check

### Autentica√ß√£o

Inclua sua API Key no header:
```
x-api-key: your-api-key
```

### Exemplos de Uso

#### 1. Scraping B√°sico (S√≠ncrono)

```bash
curl -X POST http://localhost:3000/api/scrape \
  -H "Content-Type: application/json" \
  -H "x-api-key: your-api-key" \
  -d '{
    "strategy": "basic",
    "url": "https://example.com",
    "selectors": {
      "title": {
        "query": "h1"
      },
      "links": {
        "query": "a",
        "attribute": "href",
        "multiple": true
      }
    }
  }'
```

#### 2. Screenshot

```bash
curl -X POST http://localhost:3000/api/scrape \
  -H "Content-Type: application/json" \
  -H "x-api-key: your-api-key" \
  -d '{
    "strategy": "screenshot",
    "url": "https://example.com",
    "screenshotOptions": {
      "fullPage": true,
      "type": "png"
    }
  }'
```

#### 3. Scraping Ass√≠ncrono com Webhook

```bash
curl -X POST http://localhost:3000/api/scrape/async \
  -H "Content-Type: application/json" \
  -H "x-api-key: your-api-key" \
  -d '{
    "strategy": "basic",
    "url": "https://example.com",
    "selectors": {
      "title": { "query": "h1" }
    },
    "webhook": {
      "url": "https://your-app.com/webhook",
      "method": "POST"
    },
    "priority": "high"
  }'
```

## üéØ Estrat√©gias de Scraping

### 1. Basic HTML (`basic`)
Para p√°ginas HTML est√°ticas simples.

```json
{
  "strategy": "basic",
  "url": "https://example.com",
  "selectors": {
    "title": { "query": "h1" },
    "description": { "query": ".description" }
  }
}
```

### 2. JavaScript Heavy (`javascript`)
Para p√°ginas com muito JavaScript.

```json
{
  "strategy": "javascript",
  "url": "https://spa-example.com",
  "script": "return { data: document.querySelector('.dynamic-content').textContent };"
}
```

### 3. Form Interaction (`form`)
Para intera√ß√£o com formul√°rios.

```json
{
  "strategy": "form",
  "url": "https://example.com/search",
  "interactions": [
    { "type": "type", "selector": "#search", "value": "query" },
    { "type": "click", "selector": "#submit" },
    { "type": "wait", "selector": ".results" }
  ],
  "finalSelectors": {
    "results": { "query": ".result-item", "multiple": true }
  }
}
```

### 4. Screenshot (`screenshot`)
Para captura de tela.

```json
{
  "strategy": "screenshot",
  "url": "https://example.com",
  "screenshotOptions": {
    "fullPage": true,
    "type": "png",
    "quality": 90
  }
}
```

## üê≥ Deploy com Docker

### Produ√ß√£o

```bash
# Build e start
docker-compose up -d

# Logs
docker-compose logs -f apibr

# Stop
docker-compose down
```

### Desenvolvimento

```bash
# Start em modo desenvolvimento
docker-compose --profile dev up -d apibr-dev
```

### Monitoramento (Opcional)

```bash
# Start com Prometheus e Grafana
docker-compose --profile monitoring up -d
```

- Prometheus: http://localhost:9090
- Grafana: http://localhost:3001 (admin/admin)

## üìä Monitoramento

### M√©tricas Dispon√≠veis

- Requisi√ß√µes HTTP (total, dura√ß√£o)
- Jobs de scraping (total, dura√ß√£o por estrat√©gia)
- Pool de browsers (tamanho, disponibilidade)
- Cache (opera√ß√µes, hit/miss)
- Webhooks (sucessos/falhas)

### Endpoints de Monitoramento

- `GET /api/metrics` - M√©tricas Prometheus
- `GET /api/metrics/json` - M√©tricas em JSON
- `GET /api/scrape/stats` - Stats do pool de browsers
- `GET /api/jobs` - Stats dos jobs
- `GET /health` - Health check

## üß™ Testes

```bash
# Executar todos os testes
npm test

# Testes com coverage
npm run test:coverage

# Testes em modo watch
npm run test:watch
```

## üîí Seguran√ßa

### API Keys
Configure API keys no arquivo `.env`:
```env
API_KEYS=key1,key2,key3
```

### Rate Limiting
- Limite padr√£o: 100 requests por 15 minutos
- Configur√°vel via vari√°veis de ambiente

### Headers de Seguran√ßa
- Helmet.js para headers de seguran√ßa
- CORS configurado
- Valida√ß√£o de entrada com Joi

## üöÄ Performance

### Pool de Browsers
- Reutiliza√ß√£o de inst√¢ncias do Chromium
- Gest√£o autom√°tica de recursos
- Configura√ß√£o flex√≠vel do tamanho do pool

### Cache Redis
- Cache autom√°tico de resultados
- TTL configur√°vel
- Fallback gracioso se Redis n√£o dispon√≠vel

### Otimiza√ß√µes
- Compress√£o gzip
- Timeouts configur√°veis
- Retry autom√°tico com backoff exponencial

## üõ†Ô∏è Desenvolvimento

### Estrutura do Projeto

```
src/
‚îú‚îÄ‚îÄ config/          # Configura√ß√µes
‚îú‚îÄ‚îÄ controllers/     # Controladores
‚îú‚îÄ‚îÄ domain/          # L√≥gica de dom√≠nio
‚îú‚îÄ‚îÄ infrastructure/  # Infraestrutura (cache, browsers)
‚îú‚îÄ‚îÄ middlewares/     # Middlewares
‚îú‚îÄ‚îÄ routes/          # Rotas da API
‚îú‚îÄ‚îÄ services/        # Servi√ßos
‚îú‚îÄ‚îÄ tests/           # Testes
‚îî‚îÄ‚îÄ utils/           # Utilit√°rios
```

### Scripts Dispon√≠veis

```bash
npm start          # Produ√ß√£o
npm run dev        # Desenvolvimento com watch
npm test           # Testes
npm run test:coverage  # Testes com coverage
```

## üìù Logs

### Estrutura dos Logs

```json
{
  "level": "info",
  "message": "Request completed",
  "timestamp": "2024-01-01T12:00:00.000Z",
  "method": "POST",
  "url": "/api/scrape",
  "status": 200,
  "duration": "1234ms"
}
```

### N√≠veis de Log
- `error`: Erros cr√≠ticos
- `warn`: Avisos importantes
- `info`: Informa√ß√µes gerais
- `debug`: Debug detalhado

## ü§ù Contribui√ß√£o

1. Fork o projeto
2. Crie uma branch para sua feature
3. Commit suas mudan√ßas
4. Push para a branch
5. Abra um Pull Request

## üìÑ Licen√ßa

ISC License

## üÜò Suporte

- Documenta√ß√£o: http://localhost:3000/api/docs
- Issues: [GitHub Issues]
- Email: support@apibr.com

---

**APIBR** - Sua solu√ß√£o completa para web scraping profissional! üöÄ

